# modeldb-backend

Backend for ModelDB version 2

## Prerequisites

1. General tools: git, maven, jdk 1.8

## Project build & execution steps

**Note** : This project requires **JAVA version 8** to run. Please setup and configure JAVA version 8 prior to running and then run the following steps.

### Clean workspace

```bash
mvn clean
```

### Build

#### Build but exclude JUnit Tests

```bash
mvn package -Dmaven.test.skip=true
```

#### Build maven jar artifact

There are two ways a jar can be created:

1. Stand-alone JAR generated by maven build and this jar doesn't contain other libraries. This jar is located after a successful build at `target/modeldb-1.0-SNAPSHOT.jar`.
1. Uber jar generated by spring-boot maven build, this JAR contains all the other maven libraries. This jar is located after a successful build at `target/modeldb-1.0-SNAPSHOT-client-build.jar`

#### Run

Run gRPC server using the following command

```bash
java -jar target/modeldb-1.0-SNAPSHOT-client-build.jar
```

### Running Tests

The tests require a relational database to be running. Ensure the required JDBC connector is available in pom.xml. Set the details in config.yaml

```yaml
test:
  test-database:
    DBType: relational
    RdbConfiguration:
      RdbDatabaseName: modeldb_test
      RdbDriver: "org.postgresql.Driver"
      RdbDialect: "org.hibernate.dialect.PostgreSQLDialect"
      RdbUrl: "jdbc:postgresql://localhost:5432"
      RdbUsername: postgres
      RdbPassword: root
```

Set the **VERTA_MODELDB_CONFIG** environment variable to point to config.yaml

#### Build and Run tests

```bash
mvn package
```

#### Run all JUnit tests

```bash
mvn test
```

#### Run single test

```bash
mvn -Dtest=TestName test
```

### Connecting to database

1. Provide your existing database name in config.yaml file and DB user credentials.

#### Sample

```yaml
database:
  DBType: relational
  timeout: 4
  liquibaseLockThreshold: 60 #time in second
  RdbConfiguration:
    RdbDatabaseName: modeldb
    RdbDriver: "org.postgresql.Driver"
    RdbDialect: "org.hibernate.dialect.PostgreSQLDialect"
    RdbUrl: "jdbc:postgresql://localhost:5432"
    RdbUsername: postgres
    RdbPassword: root
```

1. If you are connecting to postgres, the database needs to be already created.
1. Ensure the user mentioned in `RdbUsername` has create privileges on the database mentioned in `RdbDatabaseName`.

## Docker setup

### Docker setup & Docker Run

If you have [Docker Compose](https://docs.docker.com/compose/install/) installed, you can bring up a ModelDB server with just a couple commands.

Note the following points when the setting up docker

- Populate config.yaml file with correct information of the database engine.
- As per docker hub suggestion for the wait-for-it.sh, the following links provide documentation of wait-for-it.sh script file.
    1) <https://docs.docker.com/compose/startup-order/>
    2) <https://github.com/vishnubob/wait-for-it>

### Artifact Store gRPC server setup

Configure Host & Port number for ArtifactStore gRPC server like,

```yaml
artifactStore_grpcServer:
  host: localhost OR IP location
  port: 8086
```

#### Cloud store

If the cloud store is s3 , then backend can use the local credentials of the machine

#### Setup NFS Root File Path

```c
config.yaml --> artifactStoreConfig --> nfsRootPath : "root path"
```

### Project configuration file setup (config.yaml)

- Configure port number for ArtifactStore gRPC server : artifactStore_grpcServer --> port : 8086
- Setup cloud storage name : artifactStoreConfig --> name : amazonS3 OR googleCloudStorage OR nfs
- Setup list of bucket name : artifactStoreConfig --> buckets_names : - bucket_name
- The below configs represents example configs for various cloud artifact store methods:
```yaml
  artifactStoreType: S3
  S3:
    cloudAccessKey: <PASTE_ACCESS_KEY>
    cloudSecretKey: <PASTE_SECRET_KEY>
    cloudBucketName: <BUCKET_NAME>
    aws_region: us-east-1
```
```yaml
  artifactStoreType: S3 # This config is would allow you to use MinIO Endpoint instead of S3
  S3:
    # This config assumes connecting to a minio endpoint at localhost 9000.
    cloudAccessKey: <MINIO_USERNAME>
    cloudSecretKey: <MINIO_PASSWORD>
    cloudBucketName: <BUCKET_NAME>
    aws_region: us-east-1 # This field is not used but required to be specified because of the way S3Service is currently implemented.
    minioEndpoint: <MINIO_ENDPOINT_URL>
```
```yaml
#   Set GOOGLE_APPLICATION_CREDENTIALS Environment variable with the path to service account credentials JSON file
#   if you want to use ServiceAccountCredentials in google to authenticate. If this application is running in a
#   Google Kubernetes Engine, you can also use Google Compute Engine authentication without setting the environment variable.
#   If you are this service on a local machine and want to upload artifacts to GCS, then you will have to use a
#   service account JSON file to authenticate.
  artifactStoreType: GCS
  GCS:
    cloudBucketName: <BUCKET_NAME>
    # Default value for signedUrlValidityInMinutes is 5 minutes if signedUrlValidityInMinutes is not present in config.
    # Using the Java Duration parser to extract time. Value specified should follow ISO-8601 standard.
    #  (https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/time/Duration.html#parse(java.lang.CharSequence))
    # If you want to upload large files upto 1 GB, set the validtiy to at least 30 minutes.
    signedUrlValidity: PT5M
```

## Additional Functionaries

### Code Coverage Reports

Create code coverage reports by the following commands

```bash
mvn clean test
```

Show the created code coverage report for unit tests from following package directory, it has module wise code coverage report in 'html' format after executing unit tests

```bash
"target/site/jacoco-ut"
```

### Code analytics & coverage reports using SonarQube

Download SonarQube from the following URL

```bash
https://www.sonarqube.org/downloads/
```

How to start SonarQube for view the analytics & coverage use following URL

```bash
https://docs.sonarqube.org/latest/setup/get-started-2-minutes/
```

Create code analytics & coverage reports by the following commands

```bash
mvn clean package sonar:sonar
```

Show the created code analytics & coverage report for the project from the following link

```bash
http://localhost:9000/dashboard?id=ai.verta.modeldb%3Amodeldb
```
