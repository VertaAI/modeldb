{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DistilBERT Sentiment Classification (HuggingFace) and Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/VertaAI/modeldb/blob/master/client/workflows/demos/distilbert-sentiment-classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook walks through creating a few DistilBERT and BERT sentiment classification models, logging them to the Verta platform, and deploying them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll set up some environment variables so that the client can communicate with the Verta platform.\n",
    "\n",
    "Change these to the values in your web app profile!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['VERTA_HOST'] = \"https://CHANGEME.verta.ai/\"\n",
    "os.environ['VERTA_EMAIL'] = \"CHANGEME@CHANGEME.CHANGEME\"\n",
    "os.environ['VERTA_DEV_KEY'] = \"CHANGEME\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll make sure we have the Python libraries we need:\n",
    "- Verta for logging/deployment\n",
    "- PyTorch + HuggingFace's `transformers` for the models themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install verta torch==1.7.0 transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model has to exist before we can log and deploy it, so we will instantiate one here in our notebook.\n",
    "\n",
    "This model class will be an extensible wrapper over a [pre-trained HuggingFace classifier](https://huggingface.co/transformers/index.html).\n",
    "- `predict()` is called when the model serves predictions.\n",
    "- `describe()` is used to populate the deployed model's details in the summary page on the web app.\n",
    "- `example()` is used to supply a sample input for the model playground on the web app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    pipeline,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _ModelBase:\n",
    "    MODEL = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = pipeline(\n",
    "            task=\"sentiment-analysis\",\n",
    "            model=AutoModelForSequenceClassification.from_pretrained(self.MODEL),\n",
    "            tokenizer=AutoTokenizer.from_pretrained(self.MODEL),\n",
    "        )\n",
    "\n",
    "    def predict(self, texts):\n",
    "        return self.model(texts)\n",
    "    \n",
    "    def describe(self):\n",
    "        return {\n",
    "            'method': 'predict',\n",
    "            'args': 'texts',\n",
    "            'returns': 'sentiments',\n",
    "            'description': \"\"\"\n",
    "                Labels each sentiment as either positive or negative, along with a score for that classification.\n",
    "            \"\"\",\n",
    "            'input_description': \"\"\"\n",
    "                list[str] texts: Statements to classify.\n",
    "            \"\"\",\n",
    "            'output_description': \"\"\"\n",
    "                list[dict] sentiments: Label and score for each statement.\n",
    "                    'label' is \"POSITIVE\" or \"NEGATIVE\".\n",
    "                    'score' is a float between 0 and 1.\n",
    "            \"\"\"\n",
    "        }\n",
    "\n",
    "    def example(self):\n",
    "        return [\n",
    "            \"I like you\",\n",
    "            \"I don't like this film\",\n",
    "        ]\n",
    "\n",
    "\n",
    "class DistilBERT(_ModelBase):\n",
    "    MODEL = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "    def predict(self, texts):\n",
    "        sentiments = super(DistilBERT, self).predict(texts)\n",
    "\n",
    "        return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert = DistilBERT()\n",
    "\n",
    "texts = distilbert.example()\n",
    "print(texts)\n",
    "print(distilbert.predict(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log model to Verta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is in a good shape, we can log it to the Verta platform. First, we initialize the client to connect with the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verta import Client\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a [project](https://verta.readthedocs.io/en/master/_autogen/verta.tracking.entities.Project.html) for our text classification models,  \n",
    "an [experiment](https://verta.readthedocs.io/en/master/_autogen/verta.tracking.entities.Experiment.html) within it for models based on the DistilBERT architecture,  \n",
    "and an [experiment run](https://verta.readthedocs.io/en/master/_autogen/verta.tracking.entities.ExperimentRun.html) to associate our model with.\n",
    "\n",
    "All of these can be viewed in the Verta web app once they are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = client.get_or_create_project(\n",
    "    \"Text Classification\",\n",
    "    desc=\"Models trained for textual sentiment classification.\",\n",
    "    tags=[\"NLP\", \"Classification\", \"Q4\"],\n",
    "    attrs={'team': \"Verta\"},\n",
    ")\n",
    "\n",
    "expt = client.get_or_create_experiment(\"DistilBERT\", tags=[\"Neural Net\"])\n",
    "\n",
    "run = client.create_experiment_run(\"First DistilBERT\", tags=[\"DistilBERT\", \"English\"])\n",
    "\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the [model itself will be uploaded](https://verta.readthedocs.io/en/master/_autogen/verta.tracking.entities.ExperimentRun.html#verta.tracking.entities.ExperimentRun.log_model), along with [a list of Python libraries](https://verta.readthedocs.io/en/master/_autogen/verta.tracking.entities.ExperimentRun.html#verta.tracking.entities.ExperimentRun.log_environment) that will be required to deploy it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english\n",
    "run.log_hyperparameters({\n",
    "    'learning_rate': 1e-5,\n",
    "    'batch_size': 32,\n",
    "    'max_seq_length': 128,\n",
    "    'num_train_epochs': 3,\n",
    "})\n",
    "run.log_metric('accuracy', .913)\n",
    "\n",
    "run.log_model(distilbert, custom_modules=[])\n",
    "run.log_requirements([\"torch==1.7.0\", \"transformers\"])\n",
    "\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is uploaded to a run, it can be deployed through the web app or [via the client](https://docs.verta.ai/verta/deployment/guides/endpoint-update) as shown below, whereupon predictions can be made via a REST endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "endpoint = client.get_or_create_endpoint(path=str(uuid.uuid4()))\n",
    "endpoint.update(run, wait=True)\n",
    "\n",
    "endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions can also be made through the client!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_model = endpoint.get_deployed_model()\n",
    "\n",
    "print(texts)\n",
    "print(deployed_model.predict(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log additional models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One key aspect of the Verta platform is being able to organize your various trained models in a easy-to-navigate structure.  \n",
    "We can log additional BERT models to our project—under a new experiment—and be able to reference and deploy them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_experiment(\"BERT\", tags=[\"Neural Net\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(_ModelBase):\n",
    "    MODEL = \"textattack/bert-base-uncased-imdb\"\n",
    "\n",
    "    def predict(self, texts):\n",
    "        sentiments = super(BERT, self).predict(texts)\n",
    "\n",
    "        # fix labels\n",
    "        for sentiment in sentiments:\n",
    "            if sentiment['label'] == \"LABEL_0\":\n",
    "                sentiment['label'] = \"NEGATIVE\"\n",
    "            else:  # \"LABEL_1\"\n",
    "                sentiment['label'] = \"POSITIVE\"\n",
    "\n",
    "        return sentiments\n",
    "    \n",
    "bert = BERT()\n",
    "run = client.create_experiment_run(\n",
    "    \"First BERT\",\n",
    "    tags=[\"BERT\", \"English\"],\n",
    ")\n",
    "\n",
    "# from https://huggingface.co/textattack/bert-base-uncased-imdb\n",
    "run.log_hyperparameters({\n",
    "    'learning_rate': 2e-5,\n",
    "    'batch_size': 16,\n",
    "    'max_seq_length': 128,\n",
    "    'num_train_epochs': 5,\n",
    "})\n",
    "run.log_metric('accuracy', .89088)\n",
    "\n",
    "run.log_model(bert, custom_modules=[])\n",
    "run.log_requirements([\"torch==1.7.0\", \"transformers\"])\n",
    "\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GermanBERT(_ModelBase):\n",
    "    MODEL = \"oliverguhr/german-sentiment-bert\"\n",
    "\n",
    "    def predict(self, texts):\n",
    "        sentiments = super(GermanBERT, self).predict(texts)\n",
    "        \n",
    "        # fix labels\n",
    "        for sentiment in sentiments:\n",
    "            sentiment['label'] = sentiment['label'].upper()\n",
    "\n",
    "        return sentiments\n",
    "\n",
    "german_bert = GermanBERT()\n",
    "run = client.create_experiment_run(\n",
    "    \"German\",\n",
    "    tags=[\"BERT\", \"German\"],\n",
    ")\n",
    "\n",
    "# from http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.202.pdf\n",
    "run.log_hyperparameters({\n",
    "    'learning_rate': 2e-5,\n",
    "    'batch_size': 32,\n",
    "    'max_seq_length': 256,\n",
    "    'num_train_epochs': 3,\n",
    "})\n",
    "run.log_metric('f1', .9639)\n",
    "\n",
    "run.log_model(german_bert, custom_modules=[])\n",
    "run.log_requirements([\"torch==1.7.0\", \"transformers\"])\n",
    "\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilingualBERT(_ModelBase):\n",
    "    MODEL = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MultilingualBERT, self).__init__()\n",
    "        self.model.return_all_scores = True  # this model has 5 categories, and we'll need to make it 2\n",
    "\n",
    "\n",
    "    def predict(self, texts):\n",
    "        texts_scores = super(MultilingualBERT, self).predict(texts)\n",
    "\n",
    "        # fix labels and scores\n",
    "        sentiments = []\n",
    "        for scores in texts_scores:\n",
    "            # aggregate negative and positive scores\n",
    "            negative_scores = filter(lambda score: score['label'] in {\"1 star\", \"2 stars\", \"3 stars\"}, scores)\n",
    "            positive_scores = filter(lambda score: score['label'] in {\"4 stars\", \"5 stars\"}, scores)\n",
    "            negative_score = sum(score['score'] for score in negative_scores)\n",
    "            positive_score = sum(score['score'] for score in positive_scores)\n",
    "\n",
    "            # select greater value as sentiment\n",
    "            if positive_score > negative_score:\n",
    "                label, score = \"POSITIVE\", positive_score\n",
    "            else:\n",
    "                label, score = \"NEGATIVE\", negative_score\n",
    "            sentiments.append({'label': label, 'score': score})\n",
    "\n",
    "        return sentiments\n",
    "\n",
    "multilingual_bert = MultilingualBERT()\n",
    "run = client.create_experiment_run(\n",
    "    \"Multilingual\",\n",
    "    tags=[\"BERT\", \"English\", \"German\"],\n",
    ")\n",
    "\n",
    "# from https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment\n",
    "run.log_hyperparameters({  # example values; true hyperparameters not provided by model contributors\n",
    "    'learning_rate': 2e-5,\n",
    "    'batch_size': 16,\n",
    "    'max_seq_length': 128,\n",
    "    'num_train_epochs': 3,\n",
    "})\n",
    "run.log_metric('accuracy', .95)\n",
    "\n",
    "run.log_model(multilingual_bert, custom_modules=[])\n",
    "run.log_requirements([\"torch==1.7.0\", \"transformers\"])\n",
    "\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ...and beyond!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a handful of models logged and able to serve predictions!\n",
    "\n",
    "Feel free to use these as a starting template for your own models, and take a look at [Verta's example notebooks](https://github.com/VertaAI/modeldb/tree/master/client/workflows) for more possibilities!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
