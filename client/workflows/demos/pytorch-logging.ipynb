{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single FC-NN (PyTorch) Logging with Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is based on our [basic PyTorch example](../examples/pytorch.ipynb), using local setups of ModelDB and its client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install /path/to/verta-0.15.10-py2.py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = \"localhost:8080\"\n",
    "\n",
    "PROJECT_NAME = \"MNIST Multiclassification\"\n",
    "EXPERIMENT_NAME = \"FC-NN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_digits()\n",
    "\n",
    "X = data['data']\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.hstack((X, y.reshape(-1, 1))),\n",
    "                  columns=[\"pixel_{}\".format(i) for i in range(X.shape[-1])] + ['digit'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather indices to split training data into training and validation sets\n",
    "shuffled_idxs = np.random.permutation(len(y))\n",
    "idxs_train = shuffled_idxs[int(len(shuffled_idxs)/10):]  # last 90%\n",
    "idxs_val = shuffled_idxs[:int(len(shuffled_idxs)/10)]  # first 10%\n",
    "\n",
    "X_train, y_train = (torch.tensor(X[idxs_train], dtype=torch.float),\n",
    "                    torch.tensor(y[idxs_train], dtype=torch.long))\n",
    "X_val, y_val = (torch.tensor(X[idxs_val], dtype=torch.float),\n",
    "                torch.tensor(y[idxs_val], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Dataset object to support batch training\n",
    "class TrainingDataset(data_utils.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.features[idx], self.labels[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from verta import Client\n",
    "\n",
    "client = Client(HOST)\n",
    "proj = client.set_project(PROJECT_NAME)\n",
    "expt = client.set_experiment(EXPERIMENT_NAME)\n",
    "run = client.set_experiment_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 512\n",
    "run.log_hyperparameter(\"hidden_size\", hidden_size)\n",
    "dropout = 0.2\n",
    "run.log_hyperparameter(\"dropout\", dropout)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_features=X.shape[1],\n",
    "                 hidden_size=hidden_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc      = nn.Linear(num_features, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.output  = nn.Linear(hidden_size, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)  # flatten non-batch dimensions\n",
    "        x = func.relu(self.fc(x))\n",
    "        x = self.dropout(x)\n",
    "        x = func.softmax(self.output(x), dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify training procedure\n",
    "model = Net()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "run.log_hyperparameter(\"loss_fn\", \"cross entropy\")\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "run.log_hyperparameter(\"optimizer\", \"adam\")\n",
    "\n",
    "num_epochs = 5\n",
    "run.log_hyperparameter(\"num_epochs\", num_epochs)\n",
    "batch_size = 32\n",
    "run.log_hyperparameter(\"batch_size\", batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and Log Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable batching of training data\n",
    "dataset = TrainingDataset(X_train, y_train)\n",
    "dataloader = data_utils.DataLoader(dataset,\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_epoch in range(num_epochs):\n",
    "    for i_batch, (X_batch, y_batch) in enumerate(dataloader):\n",
    "        model.zero_grad()  # reset model gradients\n",
    "\n",
    "        output = model(X_batch)  # conduct forward pass\n",
    "\n",
    "        loss = criterion(output, y_batch)  # compare model output w/ ground truth\n",
    "        \n",
    "        print(\"\\repoch {}/{} | \".format(i_epoch+1, num_epochs), end='')\n",
    "        print(\"iteration {}/{} | \".format(i_batch+1, len(dataloader)), end='')\n",
    "        print(\"epoch loss avg: {}\".format(loss.item()), end='')\n",
    "\n",
    "        loss.backward()  # backpropogate loss to calculate gradients\n",
    "        optimizer.step()  # update model weights\n",
    "    \n",
    "    with torch.no_grad():  # no need to calculate gradients when assessing accuracy\n",
    "        print()\n",
    "        \n",
    "        pred_train = model(X_train).numpy().argmax(axis=1)\n",
    "        train_acc = (pred_train == y_train.numpy()).mean()\n",
    "        print(\"Training accuracy: {}\".format(train_acc))\n",
    "        run.log_observation(\"train_acc\", train_acc)\n",
    "        \n",
    "        pred_val = model(X_val).numpy().argmax(axis=1)\n",
    "        val_acc = (pred_val == y_val.numpy()).mean()\n",
    "        print(\"Validation accuracy: {}\".format(val_acc))\n",
    "        run.log_observation(\"val_acc\", val_acc)\n",
    "    \n",
    "    run.log_artifact(\"epoch_{}_checkpoint\".format(i_epoch), model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and Log Accuracy on Full Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # no need to calculate gradients when assessing accuracy\n",
    "    pred_train = model(X_train).numpy().argmax(axis=1)\n",
    "    train_acc = (pred_train == y_train.numpy()).mean()\n",
    "    print(\"Training accuracy: {}\".format(train_acc))\n",
    "    run.log_metric(\"train_acc\", train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Run in WebApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
