{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-of-Speech Tagging with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a quick demonstration of `verta`'s [`run.log_setup_script()`](https://verta.readthedocs.io/en/master/reference/api/experimentrun.html#verta.client.ExperimentRun.log_setup_script) feature.\n",
    "\n",
    "We'll create a simple and lightweight text tokenizer and part-of-speech tagger using NLTK,  \n",
    "which will require not only installing the `nltk` package itself,  \n",
    "but also downloading pre-trained text processing models within Python code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Verta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "\n",
    "from verta import Client\n",
    "from verta.utils import ModelAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = \"app.verta.ai\"\n",
    "\n",
    "PROJECT_NAME = \"Part-of-Speech Tagging\"\n",
    "EXPERIMENT_NAME = \"NLTK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(HOST)\n",
    "\n",
    "proj = client.set_project(PROJECT_NAME)\n",
    "expt = client.set_experiment(EXPERIMENT_NAME)\n",
    "run = client.set_experiment_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook was tested with `nltk` `v3.4.5`, though many versions should work just fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK requires the separate installation of a tokenizer and part-of-speech tagger before these functionalities can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tokenizing\n",
    "nltk.download('punkt')\n",
    "\n",
    "# for part-of-speech tagging\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Model for Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model will be a thin wrapper around `nltk`,  \n",
    "returning the constituent tokens and their part-of-speech tags for each input sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier:\n",
    "    def __init__(self, nltk):\n",
    "        self.nltk = nltk\n",
    "\n",
    "    def predict(self, data):\n",
    "        predictions = []\n",
    "        for text in data:\n",
    "            tokens = self.nltk.word_tokenize(text)\n",
    "            predictions.append({\n",
    "                'tokens': tokens,\n",
    "                'parts_of_speech': [list(pair) for pair in self.nltk.pos_tag(tokens)],\n",
    "            })\n",
    "\n",
    "        return predictions\n",
    "\n",
    "model = TextClassifier(nltk)\n",
    "\n",
    "data = [\n",
    "    \"I am a teapot.\",\n",
    "    \"Just kidding I'm a bug?\",\n",
    "]\n",
    "model.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Deployment Artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, we'll create a couple of descriptive artifacts to let the Verta platform know how to handle our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_api = ModelAPI(data, model.predict(data))\n",
    "\n",
    "run.log_model(model, model_api=model_api)\n",
    "run.log_requirements([\"nltk\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Setup Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did in the beginning of this Notebook,  \n",
    "the deployment needs these NLTK resources downloaded and installed before it can run the model,  \n",
    "so we'll define a short setup script to send over and execute at the beginning of a model deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = \"\"\"\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\"\"\"\n",
    "\n",
    "run.log_setup_script(setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Live Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visit the Web App, deploy the model, and make successful predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    \"Welcome to Verta!\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from verta.deployment import DeployedModel\n",
    "\n",
    "DeployedModel(HOST, run.id).predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
