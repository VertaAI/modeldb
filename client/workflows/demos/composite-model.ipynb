{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates how to call one deployed endpoint from another.\n",
    "\n",
    "In this scenario, two projects could be iterated on and deployed independently—one for pre-processing and one for classification—  \n",
    "and composed modularly across their endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import verta\n",
    "except ImportError:\n",
    "    !pip install verta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = \"app.verta.ai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['VERTA_EMAIL'] = \n",
    "# os.environ['VERTA_DEV_KEY'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import wget\n",
    "except ImportError:\n",
    "    !pip install wget  # you may need pip3\n",
    "    import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_url = \"http://s3.amazonaws.com/verta-starter/census-train.csv\"\n",
    "train_data_filename = wget.detect_filename(train_data_url)\n",
    "if not os.path.isfile(train_data_filename):\n",
    "    wget.download(train_data_url)\n",
    "\n",
    "test_data_url = \"http://s3.amazonaws.com/verta-starter/census-test.csv\"\n",
    "test_data_filename = wget.detect_filename(test_data_url)\n",
    "if not os.path.isfile(test_data_filename):\n",
    "    wget.download(test_data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_data_filename)\n",
    "X_train = df_train.iloc[:,:-1]\n",
    "y_train = df_train.iloc[:, -1]\n",
    "\n",
    "df_test = pd.read_csv(test_data_filename)\n",
    "X_test = df_test.iloc[:,:-1]\n",
    "y_test = df_test.iloc[:, -1]\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verta import Client\n",
    "\n",
    "client = Client(HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self, preprocessor):\n",
    "        self.preprocessor = preprocessor\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.preprocessor.transform(x)\n",
    "    \n",
    "    def example(self):\n",
    "        return [\n",
    "            [44, 0, 0, 40, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
    "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "client.get_or_create_project(\"Preprocessor\")\n",
    "client.get_or_create_experiment(\"Normalization\")\n",
    "run = client.get_or_create_experiment_run()\n",
    "\n",
    "preprocessor = preprocessing.Normalizer()\n",
    "run.log_model(Preprocessor(preprocessor))\n",
    "run.log_requirements(['sklearn'])\n",
    "\n",
    "endpoint = client.get_or_create_endpoint(\"ml-preprocessor\")\n",
    "endpoint.update(run, wait=True)\n",
    "endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:    \n",
    "    def __init__(self, classifier):\n",
    "        self.classifier = classifier\n",
    "    \n",
    "    def predict(self, x):\n",
    "        import requests\n",
    "        \n",
    "        response = requests.post(\n",
    "            \"https://{}/api/v1/predict/ml-preprocessor\".format(HOST),\n",
    "            json=x,\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        transformed_x = response.json()\n",
    "        return self.classifier.predict(transformed_x)\n",
    "    \n",
    "    def example(self):\n",
    "        return [\n",
    "            [0.7396263843801948, 0.0, 0.0, 0.6723876221638134, 0.0, 0.016809690554095334, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "             0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016809690554095334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "             0.0, 0.0, 0.0, 0.016809690554095334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_or_create_project(\"Classifier\")\n",
    "client.get_or_create_experiment(\"Logistic Regression\")\n",
    "run = client.get_or_create_experiment_run()\n",
    "\n",
    "classifier = linear_model.LogisticRegression(max_iter=10**5)\n",
    "classifier.fit(preprocessor.transform(X_train), y_train)\n",
    "run.log_model(Classifier(classifier))\n",
    "run.log_requirements(['sklearn'])\n",
    "\n",
    "endpoint = client.get_or_create_endpoint(\"ml-classifier\")\n",
    "endpoint.update(run, wait=True)\n",
    "endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_model = endpoint.get_deployed_model()\n",
    "\n",
    "for row in itertools.cycle(X_test.values):\n",
    "    print(deployed_model.predict([row]))\n",
    "    time.sleep(.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
