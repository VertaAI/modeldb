{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Versioning Example (Part 2/3)\n",
    "In part 1, we trained and logged a tweet sentiment classifier using ModelDB's versioning system.\n",
    "\n",
    "Now we'll see how that can come in handy when we need to revisit or even revert changes we make.\n",
    "\n",
    "This workflow requires ``verta>=0.14.1`` and ``spaCy>=2.0.0``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, import libraries we'll need..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and instantiate Verta's ModelDB Client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set email from environment\n",
      "set developer key from environment\n",
      "connection successfully established\n",
      "set existing Project: Tweet Classification from personal workspace\n",
      "set existing Experiment: SpaCy\n"
     ]
    }
   ],
   "source": [
    "from verta import Client\n",
    "\n",
    "client = Client('https://app.verta.ai')\n",
    "proj = client.set_project('Tweet Classification')\n",
    "expt = client.set_experiment('SpaCy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data\n",
    "This time, things are a little different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say someone has provided us with a new, expermental dataset that supposedly will improve our model. Unbeknownst to everyone, this dataset actually only contains *one* of the two classes we're interested in. This is going to hurt our performance, but we don't know it yet.\n",
    "\n",
    "Before, we trained a model on `english-tweets.csv`. Now, we're going to train with **`positive-english-tweets.csv`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_BUCKET = \"verta-starter\"\n",
    "S3_KEY = \"positive-english-tweets.csv\"\n",
    "FILENAME = S3_KEY\n",
    "\n",
    "boto3.client('s3').download_file(S3_BUCKET, S3_KEY, FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sean Lock is awesome !! ... I love Family Guy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Date night with Jared! At the movies!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ohac track 2 Tirthankar says you should partic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>long weekend</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drawing. Slightly irritated. Oh well nothing I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  Sean Lock is awesome !! ... I love Family Guy ...          1\n",
       "1              Date night with Jared! At the movies!          1\n",
       "2  ohac track 2 Tirthankar says you should partic...          1\n",
       "3                                       long weekend          1\n",
       "4  Drawing. Slightly irritated. Oh well nothing I...          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "data = pd.read_csv(FILENAME).sample(frac=1).reset_index(drop=True)\n",
    "utils.clean_data(data)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capture and Version Model Ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with before, we'll capture and log our model ingredients directly onto our repository's `master` branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    require([\"base/js/namespace\"],function(Jupyter) {\n",
       "        Jupyter.notebook.save_checkpoint();\n",
       "    });\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from verta.code import Notebook\n",
    "from verta.configuration import Hyperparameters\n",
    "from verta.dataset import S3\n",
    "from verta.environment import Python\n",
    "\n",
    "code_ver = Notebook()  # Notebook & git environment\n",
    "config_ver = Hyperparameters({'n_iter': 20})\n",
    "dataset_ver = S3(\"s3://{}/{}\".format(S3_BUCKET, S3_KEY))\n",
    "env_ver = Python(Python.read_pip_environment())  # pip environment and Python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set existing Repository: Tweet Classification from personal workspace\n"
     ]
    }
   ],
   "source": [
    "repo = client.set_repository('Tweet Classification')\n",
    "commit = repo.get_commit(branch='master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    require([\"base/js/namespace\"],function(Jupyter) {\n",
       "        Jupyter.notebook.save_checkpoint();\n",
       "    });\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    require([\"base/js/namespace\"],function(Jupyter) {\n",
       "        Jupyter.notebook.save_checkpoint();\n",
       "    });\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(Branch: master)\n",
       "Commit 62d20618f919d6ebaa389caea39e3cf27cad6e7cc5b18cc9248935e2432da27d containing:\n",
       "config/hyperparams (Hyperparameters)\n",
       "data/tweets (S3)\n",
       "env/python (Python)\n",
       "notebooks/tweet-analysis (Notebook)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commit.update(\"notebooks/tweet-analysis\", code_ver)\n",
    "commit.update(\"config/hyperparams\", config_ver)\n",
    "commit.update(\"data/tweets\", dataset_ver)\n",
    "commit.update(\"env/python\", env_ver)\n",
    "\n",
    "commit.save(\"Update tweet dataset\")\n",
    "\n",
    "commit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may verify through [the Web App](https://app.verta.ai/) that this commit updates the dataset, as well as the Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Log Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again as before, we'll train the model and log it along with the commit to an Experiment Run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 16000 examples (12800 training, 3200 evaluation)\n",
      "Training the model...\n",
      "LOSS \t  P  \t  R  \t  F  \n",
      "0.215\t1.000\t1.000\t1.000\n",
      "0.001\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n"
     ]
    }
   ],
   "source": [
    "import training\n",
    "\n",
    "training.train(nlp, data, n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created new ExperimentRun: Run 421651584660604710162\n",
      "upload complete (custom_modules.zip)\n",
      "upload complete (model.pkl)\n",
      "upload complete (model_api.json)\n"
     ]
    }
   ],
   "source": [
    "run = client.set_experiment_run()\n",
    "\n",
    "run.log_model(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_commit(\n",
    "    commit,\n",
    "    {\n",
    "        'notebook': \"notebooks/tweet-analysis\",\n",
    "        'hyperparameters': \"config/hyperparams\",\n",
    "        'training_data': \"data/tweets\",\n",
    "        'python_env': \"env/python\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revert Commit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking back over our workflow, we might notice that there's something suspicious about the model's precision, recall, and F-score. This model isn't performing as it should, and we don't want it to be the latest commit in `master`. Using the Client, we'll revert the commit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Branch: master)\n",
       "Commit 62d20618f919d6ebaa389caea39e3cf27cad6e7cc5b18cc9248935e2432da27d containing:\n",
       "config/hyperparams (Hyperparameters)\n",
       "data/tweets (S3)\n",
       "env/python (Python)\n",
       "notebooks/tweet-analysis (Notebook)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    require([\"base/js/namespace\"],function(Jupyter) {\n",
       "        Jupyter.notebook.save_checkpoint();\n",
       "    });\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(Branch: master)\n",
       "Commit 0760381007ec1f0f9a452b7d61c2d385476c6a6727b3aaac028c6abb53417010 containing:\n",
       "config/hyperparams (Hyperparameters)\n",
       "data/tweets (S3)\n",
       "env/python (Python)\n",
       "notebooks/tweet-analysis (Notebook)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commit.revert()\n",
    "\n",
    "commit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As easy as thatâ€”we have a new commit on `master` that reverted our grave mistake.\n",
    "\n",
    "Again, [the Web App](https://app.verta.ai/) will show that the change from `english-tweets.csv` to `positive-english-tweets.csv` has been undone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
