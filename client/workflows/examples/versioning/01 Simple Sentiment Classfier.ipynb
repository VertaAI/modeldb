{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Versioning Example (Part 1/3)\n",
    "In this example, we'll train an NLP model for sentiment analysis of tweets using spaCy.\n",
    "\n",
    "Through this series, we'll take advantage of ModelDB's versioning system to keep track of changes.\n",
    "\n",
    "This workflow requires `verta>=0.14.1` and `spaCy>=2.0.0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download a spaCy model to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: thinc==7.4.0 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: setuptools in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (41.2.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.43.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring in Verta's ModelDB client to organize our work, and log and version metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set email from environment\n",
      "set developer key from environment\n",
      "connection successfully established\n",
      "set existing Project: Tweet Classification from personal workspace\n",
      "set existing Experiment: SpaCy\n"
     ]
    }
   ],
   "source": [
    "from verta import Client\n",
    "\n",
    "client = Client('https://app.verta.ai')\n",
    "proj = client.set_project('Tweet Classification')\n",
    "expt = client.set_experiment('SpaCy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download a dataset of English tweets from S3 for us to train with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_BUCKET = \"verta-starter\"\n",
    "S3_KEY = \"english-tweets.csv\"\n",
    "FILENAME = S3_KEY\n",
    "\n",
    "boto3.client('s3').download_file(S3_BUCKET, S3_KEY, FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll load and clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the price of fame</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My company (toggle, who powers anderra) has ju...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the littlest prince- im rereading it, its been...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that hit makes me sad  poor welker. hes a toug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>byebye everyone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0                                  the price of fame          0\n",
       "1  My company (toggle, who powers anderra) has ju...          1\n",
       "2  the littlest prince- im rereading it, its been...          1\n",
       "3  that hit makes me sad  poor welker. hes a toug...          0\n",
       "4                                   byebye everyone.          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "data = pd.read_csv(FILENAME).sample(frac=1).reset_index(drop=True)\n",
    "utils.clean_data(data)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capture and Version Model Ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first capture metadata about our code, configuration, dataset, and environment using utilities from the `verta` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    require([\"base/js/namespace\"],function(Jupyter) {\n",
       "        Jupyter.notebook.save_checkpoint();\n",
       "    });\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from verta.code import Notebook\n",
    "from verta.configuration import Hyperparameters\n",
    "from verta.dataset import S3\n",
    "from verta.environment import Python\n",
    "\n",
    "code_ver = Notebook()  # Notebook & git environment\n",
    "config_ver = Hyperparameters({'n_iter': 20})\n",
    "dataset_ver = S3(\"s3://{}/{}\".format(S3_BUCKET, S3_KEY))\n",
    "env_ver = Python(Python.read_pip_environment())  # pip environment and Python version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, to log them, we'll use a ModelDB repository to prepare a commit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set existing Repository: Tweet Classification from personal workspace\n"
     ]
    }
   ],
   "source": [
    "repo = client.set_repository('Tweet Classification')\n",
    "commit = repo.get_commit(branch='master')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll add these versioned components to the commit and save it to ModelDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    require([\"base/js/namespace\"],function(Jupyter) {\n",
       "        Jupyter.notebook.save_checkpoint();\n",
       "    });\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    require([\"base/js/namespace\"],function(Jupyter) {\n",
       "        Jupyter.notebook.save_checkpoint();\n",
       "    });\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(Branch: master)\n",
       "Commit e9f25d8206115119d202c62f540a60e6d988615e6c96e9c0701b67b8b5c2c9f9 containing:\n",
       "config/hyperparams (Hyperparameters)\n",
       "data/tweets (S3)\n",
       "env/python (Python)\n",
       "notebooks/tweet-analysis (Notebook)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commit.update(\"notebooks/tweet-analysis\", code_ver)\n",
    "commit.update(\"config/hyperparams\", config_ver)\n",
    "commit.update(\"data/tweets\", dataset_ver)\n",
    "commit.update(\"env/python\", env_ver)\n",
    "\n",
    "commit.save(\"Initial model\")\n",
    "\n",
    "commit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Log Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the pre-trained spaCy model we downloaded earlier..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and fine-tune it with our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 16000 examples (12800 training, 3200 evaluation)\n",
      "Training the model...\n",
      "LOSS \t  P  \t  R  \t  F  \n",
      "16.369\t0.729\t0.707\t0.717\n",
      "0.360\t0.744\t0.729\t0.736\n",
      "0.105\t0.746\t0.734\t0.740\n",
      "0.089\t0.751\t0.739\t0.745\n",
      "0.076\t0.759\t0.734\t0.746\n",
      "0.066\t0.751\t0.730\t0.740\n",
      "0.057\t0.747\t0.733\t0.740\n",
      "0.046\t0.742\t0.721\t0.731\n",
      "0.042\t0.744\t0.722\t0.733\n",
      "0.035\t0.741\t0.719\t0.730\n",
      "0.031\t0.742\t0.709\t0.725\n",
      "0.027\t0.737\t0.715\t0.726\n",
      "0.023\t0.733\t0.712\t0.723\n",
      "0.022\t0.735\t0.721\t0.728\n",
      "0.021\t0.737\t0.712\t0.725\n",
      "0.019\t0.742\t0.712\t0.726\n",
      "0.016\t0.747\t0.722\t0.734\n",
      "0.018\t0.745\t0.720\t0.732\n",
      "0.015\t0.744\t0.719\t0.731\n",
      "0.014\t0.739\t0.719\t0.729\n"
     ]
    }
   ],
   "source": [
    "import training\n",
    "\n",
    "training.train(nlp, data, n_iter=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our model is good to go, we'll log it to ModelDB so our progress is never lost.\n",
    "\n",
    "Using Verta's ModelDB Client, we'll create an Experiment Run to encapsulate our work, and log our model as an artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created new ExperimentRun: Run 421821584660637939761\n",
      "upload complete (custom_modules.zip)\n",
      "upload complete (model.pkl)\n",
      "upload complete (model_api.json)\n"
     ]
    }
   ],
   "source": [
    "run = client.set_experiment_run()\n",
    "\n",
    "run.log_model(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we'll link the commit we created earlier to the Experiment Run to complete our logged model version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_commit(\n",
    "    commit,\n",
    "    {\n",
    "        'notebook': \"notebooks/tweet-analysis\",\n",
    "        'hyperparameters': \"config/hyperparams\",\n",
    "        'training_data': \"data/tweets\",\n",
    "        'python_env': \"env/python\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've consolidated all the information we would need to reproduce this model later, or revisit the work we've done!\n",
    "\n",
    "Proceed to the second notebook to see how problematic commits can be reverted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
