{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Versioning Example (Part 3/3)\n",
    "In part 2, we trained and logged a problematic model, and then reverted the commit to restore a good version.\n",
    "\n",
    "Now we'll train an even better model—one that can also classify tweets in German—but this time using a separate branch and merge, instead of committing directly to `master`.\n",
    "\n",
    "This workflow requires ``verta>=0.14.4`` and ``spaCy>=2.0.0``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of spaCy's English model, we'll be building off of **a multilingual model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xx_ent_wiki_sm==2.2.0 from https://github.com/explosion/spacy-models/releases/download/xx_ent_wiki_sm-2.2.0/xx_ent_wiki_sm-2.2.0.tar.gz#egg=xx_ent_wiki_sm==2.2.0 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (2.2.0)\n",
      "Requirement already satisfied: spacy>=2.2.0 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from xx_ent_wiki_sm==2.2.0) (2.2.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (41.2.0)\n",
      "Requirement already satisfied: thinc==7.4.0 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (7.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (3.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (1.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (4.43.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (2.0.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (1.0.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (0.6.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (2.23.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (1.18.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (0.4.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (1.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (1.5.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (2019.11.28)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/miliu/Documents/modeldb/client/workflows/venv-flow/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('xx_ent_wiki_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download xx_ent_wiki_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as before, import libraries we'll need..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and instantiate Verta's ModelDB Client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set email from environment\n",
      "set developer key from environment\n",
      "connection successfully established\n",
      "set existing Project: Tweet Classification from personal workspace\n",
      "set existing Experiment: SpaCy\n"
     ]
    }
   ],
   "source": [
    "from verta import Client\n",
    "\n",
    "client = Client('http://localhost:3000/')\n",
    "proj = client.set_project('Tweet Classification')\n",
    "expt = client.set_experiment('SpaCy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data\n",
    "Again, things are a little different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our multilingual model needs German training data to classify German tweet, so we'll download two datasets from S3.\n",
    "\n",
    "Before, we trained a model on just `english-tweets.csv`. Now, we're going to _also_ train with **`german-tweets.csv`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_BUCKET = \"verta-starter\"\n",
    "EN_S3_KEY = \"english-tweets.csv\"\n",
    "EN_FILENAME = EN_S3_KEY\n",
    "DE_S3_KEY = \"german-tweets.csv\"\n",
    "DE_FILENAME = DE_S3_KEY\n",
    "\n",
    "boto3.client('s3').download_file(S3_BUCKET, EN_S3_KEY, EN_FILENAME)\n",
    "boto3.client('s3').download_file(S3_BUCKET, DE_S3_KEY, DE_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is so weird. Being back here makes me mis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Me too  I couldn't button my jeans today....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i can't believe janice got voted off  lameeeeeeee</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it's not summer yet!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are welcome!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  This is so weird. Being back here makes me mis...          0\n",
       "1       Me too  I couldn't button my jeans today....          0\n",
       "2  i can't believe janice got voted off  lameeeeeeee          0\n",
       "3                               it's not summer yet!          0\n",
       "4                                   You are welcome!          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "en_data = pd.read_csv(EN_FILENAME)\n",
    "de_data = pd.read_csv(DE_FILENAME)\n",
    "\n",
    "data = pd.concat([en_data, de_data], axis=0)\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "utils.clean_data(data)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capture and Version Model Ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with before, we'll capture and log our model ingredients. Note that now we're logging **both** of our datasets from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    require([\"base/js/namespace\"],function(Jupyter) {\n",
       "        Jupyter.notebook.save_checkpoint();\n",
       "    });\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from verta.code import Notebook\n",
    "from verta.configuration import Hyperparameters\n",
    "from verta.dataset import S3\n",
    "from verta.environment import Python\n",
    "\n",
    "code_ver = Notebook()  # Notebook & git environment\n",
    "config_ver = Hyperparameters({'n_iter': 20})\n",
    "dataset_ver = S3([\n",
    "    \"s3://{}/{}\".format(S3_BUCKET, EN_S3_KEY),\n",
    "    \"s3://{}/{}\".format(S3_BUCKET, DE_S3_KEY),\n",
    "])\n",
    "env_ver = Python(Python.read_pip_environment())  # pip environment and Python version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But instead of committing directly to master, we'll checkout and commit to a separate branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set existing Repository: Tweet Classification from personal workspace\n"
     ]
    }
   ],
   "source": [
    "repo = client.set_repository('Tweet Classification')\n",
    "commit = repo.get_commit(branch='master').new_branch('multilingual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    require([\"base/js/namespace\"],function(Jupyter) {\n",
       "        Jupyter.notebook.save_checkpoint();\n",
       "    });\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    require([\"base/js/namespace\"],function(Jupyter) {\n",
       "        Jupyter.notebook.save_checkpoint();\n",
       "    });\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(Branch: multilingual)\n",
       "Commit 92bf1a8d4c7e5c4dc8f00fcea5748e90023791f50f37c261fb977e630daba6ca containing:\n",
       "config/hyperparams (Hyperparameters)\n",
       "data/tweets (S3)\n",
       "env/python (Python)\n",
       "notebooks/tweet-analysis (Notebook)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commit.update(\"notebooks/tweet-analysis\", code_ver)\n",
    "commit.update(\"config/hyperparams\", config_ver)\n",
    "commit.update(\"data/tweets\", dataset_ver)\n",
    "commit.update(\"env/python\", env_ver)\n",
    "\n",
    "commit.save(\"Support German tweets\")\n",
    "\n",
    "commit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may verify through [the Web App](http://localhost:3000/) that this commit—on branch `multilingual`—updates the dataset, as well as the Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Log Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again as before, we'll train the model and log it along with the commit to an Experiment Run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('xx_ent_wiki_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 16000 examples (12800 training, 3200 evaluation)\n",
      "Training the model...\n",
      "LOSS \t  P  \t  R  \t  F  \n",
      "16.027\t0.752\t0.764\t0.758\n",
      "0.361\t0.775\t0.744\t0.759\n",
      "0.104\t0.791\t0.737\t0.763\n",
      "0.090\t0.790\t0.729\t0.758\n",
      "0.079\t0.783\t0.732\t0.757\n",
      "0.067\t0.787\t0.726\t0.756\n",
      "0.058\t0.778\t0.723\t0.749\n",
      "0.047\t0.777\t0.718\t0.746\n",
      "0.042\t0.777\t0.726\t0.751\n",
      "0.034\t0.769\t0.725\t0.747\n",
      "0.030\t0.766\t0.729\t0.747\n",
      "0.026\t0.766\t0.728\t0.746\n",
      "0.024\t0.765\t0.729\t0.747\n",
      "0.022\t0.765\t0.729\t0.746\n",
      "0.020\t0.765\t0.720\t0.742\n",
      "0.019\t0.766\t0.718\t0.741\n",
      "0.018\t0.765\t0.715\t0.739\n",
      "0.017\t0.759\t0.715\t0.736\n",
      "0.015\t0.762\t0.718\t0.739\n",
      "0.015\t0.764\t0.721\t0.742\n"
     ]
    }
   ],
   "source": [
    "import training\n",
    "\n",
    "training.train(nlp, data, n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created new ExperimentRun: Run 4342615846618541268559\n",
      "upload complete (custom_modules.zip)\n",
      "upload complete (model.pkl)\n",
      "upload complete (model_api.json)\n"
     ]
    }
   ],
   "source": [
    "run = client.set_experiment_run()\n",
    "\n",
    "run.log_model(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_commit(\n",
    "    commit,\n",
    "    {\n",
    "        'notebook': \"notebooks/tweet-analysis\",\n",
    "        'hyperparameters': \"config/hyperparams\",\n",
    "        'training_data': \"data/tweets\",\n",
    "        'python_env': \"env/python\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Commit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model seems to be handling our multilingual data just fine, so we'll merge our improvements into `master`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Branch: multilingual)\n",
       "Commit 92bf1a8d4c7e5c4dc8f00fcea5748e90023791f50f37c261fb977e630daba6ca containing:\n",
       "config/hyperparams (Hyperparameters)\n",
       "data/tweets (S3)\n",
       "env/python (Python)\n",
       "notebooks/tweet-analysis (Notebook)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    require([\"base/js/namespace\"],function(Jupyter) {\n",
       "        Jupyter.notebook.save_checkpoint();\n",
       "    });\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(Branch: master)\n",
       "Commit e9f25d8206115119d202c62f540a60e6d988615e6c96e9c0701b67b8b5c2c9f9 containing:\n",
       "config/hyperparams (Hyperparameters)\n",
       "data/tweets (S3)\n",
       "env/python (Python)\n",
       "notebooks/tweet-analysis (Notebook)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master = repo.get_commit(branch=\"master\")\n",
    "\n",
    "master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    require([\"base/js/namespace\"],function(Jupyter) {\n",
       "        Jupyter.notebook.save_checkpoint();\n",
       "    });\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(Branch: master)\n",
       "Commit 99774bcc3b84d420340c02346130713627f900dca165580210d2fd6d8094fb73 containing:\n",
       "config/hyperparams (Hyperparameters)\n",
       "data/tweets (S3)\n",
       "env/python (Python)\n",
       "notebooks/tweet-analysis (Notebook)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.merge(commit)\n",
    "\n",
    "master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've merged `multilingual` into `master`, bringing in our verified and proven changes.\n",
    "\n",
    "Again, [the Web App](http://localhost:3000/) will show this merge commit on `master` updating the dataset and the Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
